# podcast-transcription-segmentation
End-to-end system for podcast audio cleaning, Whisper transcription, topic segmentation, keyword extraction, and interactive transcript navigation â€” using AMI audio as dataset. Includes preprocessing, ASR, NLP modeling, visualization, and UI.

ğŸ§ Podcast Transcription, Segmentation & HR-Interview Summarization Pipeline

This project implements an end-to-end Audio â†’ Segmentation â†’ ASR â†’ Summarization system designed for:

Podcast processing

HR interview analysis

Meeting & conversation summarization

Speaker-wise transcript generation

Segment-level insights & metrics

It uses AMI Meeting Corpus as the primary dataset and integrates state-of-the-art ASR models, NLP pipelines, and deep-learning based segmentation.

ğŸš€ Project Features
ğŸ”Š 1. Audio Preprocessing

Standardizes sampling rate (16kHz)

Denoising, normalization

Works with long audio files (1â€“2 hours)

âœ‚ï¸ 2. Audio Segmentation

Silence-based segmentation

Energy-based segmentation

Optional VAD-based (Voice Activity Detection)

Handles noisy interviews and long meetings

ğŸ—£ï¸ 3. Automatic Speech Recognition (ASR)

Supports multiple ASR backends:

Whisper Large-V3 / Medium / Small

NeMo CTC models

Wav2Vec2-based models

Outputs:

Full transcript

Timestamped transcript

Segment-wise transcript

ğŸ§‘â€ğŸ¤â€ğŸ§‘ 4. Speaker Diarization (Optional)

pyannote.audio diarization

Outputs speaker-annotated transcript:
(SPEAKER A: â€¦ | SPEAKER B: â€¦)

ğŸ“ 5. Summarization Pipeline

Generates:

Overall summary

Segment-wise summaries

Speaker-wise summaries

Key topics

Keywords

Q&A extraction

Sentiment & emotion analysis

ğŸ“Š 6. HR Interviewâ€“Specific Analytics

Candidate performance indicators

Interviewer-candidate talk ratio

Question complexity extraction

Behavioral signal insights

STAR method summary (Situationâ€“Taskâ€“Actionâ€“Result)

ğŸ—‚ï¸ Dataset Used (AMI Meeting Corpus)

Example loaded files:

ES2002a.Mix-Lapel.wav  
ES2002b.Mix-Lapel.wav  
ES2002c.Mix-Lapel.wav  
ES2002d.Mix-Lapel.wav  


Why AMI?

High-quality multi-speaker meetings

Long-form conversational structure (similar to HR interviews)

Fully transcribed

âš™ï¸ Tech Stack
Component	Technology
Language	Python 3.10+
ASR	OpenAI Whisper, Wav2Vec2
Segmentation	PyDub, WebRTC VAD
Diarization	pyannote.audio
Summarization	Transformers / GPT models
Visualization	Matplotlib, Plotly
Data Storage	JSON, CSV, TXT
ğŸ§© Pipeline Architecture
Audio Input (.wav)
        â†“
Segmentation (silence / VAD)
        â†“
ASR Transcription
        â†“
(Optional) Diarization
        â†“
NLP Processing (Summaries, Topics, Q&A)
        â†“
Outputs â†’ JSON, TXT, CSV

ğŸ“ Folder Structure (Recommended)
project-root/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_audio/
â”‚   â”‚   â”œâ”€â”€ ES2002a.Mix-Lapel.wav
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ segments/
â”‚   â”œâ”€â”€ transcripts/
â”‚   â””â”€â”€ summaries/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_audio_loading.ipynb
â”‚   â”œâ”€â”€ 02_segmentation.ipynb
â”‚   â”œâ”€â”€ 03_asr_transcription.ipynb
â”‚   â”œâ”€â”€ 04_summarization.ipynb
â”‚   â””â”€â”€ 05_hr_interview_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ audio_preprocess.py
â”‚   â”œâ”€â”€ segmentation/
â”‚   â”‚   â””â”€â”€ vad_segmentation.py
â”‚   â”œâ”€â”€ asr/
â”‚   â”‚   â””â”€â”€ whisper_transcriber.py
â”‚   â”œâ”€â”€ summarization/
â”‚   â”‚   â””â”€â”€ summary_pipeline.py
â”‚   â”œâ”€â”€ hr_analysis/
â”‚   â”‚   â””â”€â”€ interview_metrics.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ (Saved ASR models, diarization models)
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ main.py

â–¶ï¸ How to Run

Install dependencies:
pip install -r requirements.txt


Run entire pipeline:
python main.py --audio data/raw_audio/ES2002a.Mix-Lapel.wav


Outputs stored in:

/data/transcripts  
/data/summaries  
/data/segments  

ğŸ“Œ Project Outcomes
End-to-end HR interview analysis system
Long-form audio handling + segmentation
Accurate transcripts

High-quality summarization

Useful analytics for recruiters

Ready for deployment in HR tech tools

ğŸ—ï¸ Future Improvements

Real-time segmentation & ASR

UI dashboard

Fine-tuned ASR for HR interviews

Large-Scale multi-speaker diarization

ğŸ“œ License

MIT License (customize if needed)

âœ… 2. GitHub Folder Structure (Short Form)
ğŸ“¦ Podcast-HR-Interview-Analysis
 â”£ ğŸ“‚ data
 â”£ ğŸ“‚ notebooks
 â”£ ğŸ“‚ src
 â”£ ğŸ“‚ models
 â”£ ğŸ“œ README.md
 â”£ ğŸ“œ requirements.txt
 â”— ğŸ“œ main.py


ğŸš€ 3. Steps to Push Code to GitHub
Step 1 â€“ Initialize repo
git init
git branch -M main

Step 2 â€“ Add remote GitHub repo
git remote add origin https://github.com/VanshikaKumawat/podcast-transcription-segmentation.git

Step 3 â€“ Add files
git add .

Step 4 â€“ Commit
git commit -m "Initial commit: audio pipeline project"

Step 5 â€“ Push
git push -u origin main
